{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cinnabar.plotting import _master_plot\n",
    "from cinnabar import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the basic edge data\n",
    "cumulative_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/processed_results/combined_pymbar3_cumulative_data.csv\")\n",
    "# load our edge data with exp values\n",
    "normal_edge_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/processed_results/combined_pymbar3_edge_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rerun data\n",
    "rerun_cumulative_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/processed_results/reruns/rerun_pymbar3_cumulative_data.csv\")\n",
    "# load the rerun edge data with exp values\n",
    "rerun_edge_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/processed_results/reruns/rerun_pymbar3_edge_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the pfkfb3 data from the default and add the rerun data\n",
    "cumulative_data = cumulative_data[cumulative_data[\"system name\"] != \"pfkfb3\"]\n",
    "cumulative_data = pd.concat([cumulative_data, rerun_cumulative_data], ignore_index=True)\n",
    "# drop the pfkfb3 data from the default and add the rerun data\n",
    "normal_edge_data = normal_edge_data[(normal_edge_data[\"system name\"] != \"pfkfb3\")]\n",
    "normal_edge_data = pd.concat([normal_edge_data, rerun_edge_data], ignore_index=True)\n",
    "normal_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the private edge and cumulative data\n",
    "private_cumulative_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/private_processed_results/combined_pymbar3_cumulative_data.csv\")\n",
    "private_edge_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/private_processed_results/combined_pymbar3_edge_data.csv\")\n",
    "private_edge_data = private_edge_data[private_edge_data[\"failed\"] != True]\n",
    "private_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dg data\n",
    "public_dg_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/processed_results/combined_pymbar3_calculated_dg_data.csv\")\n",
    "private_dg_data = pd.read_csv(\"https://raw.githubusercontent.com/OpenFreeEnergy/IndustryBenchmarks2024/refs/heads/main/industry_benchmarks/analysis/private_processed_results/combined_pymbar3_calculated_dg_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean ddg uncertainty for the public and private data \n",
    "public_complex_data = normal_edge_data[[f\"complex_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "public_solvent_data = normal_edge_data[[f\"solvent_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "private_complex_data = private_edge_data[[f\"complex_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "private_solvent_data = private_edge_data[[f\"solvent_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "public_uncertainty = (public_complex_data.std(axis=1) ** 2 + public_solvent_data.std(axis=1) **2) ** 0.5\n",
    "print(public_uncertainty.mean())\n",
    "private_uncertainty = (private_complex_data.std(axis=1) ** 2 + private_solvent_data.std(axis=1) **2) ** 0.5\n",
    "print(private_uncertainty.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cumulative data has each phase and repeat on a new line\n",
    "# create a new csv with the DDG prediction for the edge after each ns + the error\n",
    "per_ns_ddgs_neutral, per_ns_ddgs_charged = [], []\n",
    "for _, row in normal_edge_data.iterrows():\n",
    "    if row[\"alchemical_charge_difference\"] == 0:\n",
    "        total_ns = 5\n",
    "    else:\n",
    "        total_ns = 20\n",
    "    cumulative_data_row = {\n",
    "        \"system group\": row[\"system group\"],\n",
    "        \"system name\": row[\"system name\"],\n",
    "        \"ligand_A\": row[\"ligand_A\"],\n",
    "        \"ligand_B\": row[\"ligand_B\"],\n",
    "        \"exp DDG (kcal/mol)\": row[\"exp DDG (kcal/mol)\"],\n",
    "        \"exp dDDG (kcal/mol)\": row[\"exp dDDG (kcal/mol)\"],\n",
    "        \"alchemical_charge_difference\": row[\"alchemical_charge_difference\"]\n",
    "    }\n",
    "    # workout the estimate of DDG for each ns\n",
    "    temp_cumulative_data = cumulative_data[(cumulative_data[\"system group\"] == row[\"system group\"]) & (cumulative_data[\"system name\"] == row[\"system name\"])].copy(deep=True).reset_index(drop=True)\n",
    "    complex_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"complex\")]\n",
    "    solvent_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"solvent\")]\n",
    "\n",
    "    for i in range(1, total_ns + 1):\n",
    "        per_ns_complex = complex_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_complex_error = complex_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        per_ns_solvent = solvent_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_solvent_error = solvent_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        cumulative_data_row[f\"Samples {i} ns DDG\"] = per_ns_complex - per_ns_solvent\n",
    "        cumulative_data_row[f\"Samples {i} ns dDDG\"] = (per_ns_complex_error ** 2 + per_ns_solvent_error ** 2) ** 0.5\n",
    "    # workout where to store the row\n",
    "    if total_ns == 5:\n",
    "        per_ns_ddgs_neutral.append(cumulative_data_row)\n",
    "    else:\n",
    "        per_ns_ddgs_charged.append(cumulative_data_row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again for the private data\n",
    "per_ns_ddgs_neutral_private, per_ns_ddgs_charged_private = [], []\n",
    "for _, row in private_edge_data.iterrows():\n",
    "    # skip the intermediates\n",
    "    if pd.isna(row[\"exp DDG (kcal/mol)\"]):\n",
    "        continue\n",
    "    if row[\"alchemical_charge_difference\"] == 0:\n",
    "        total_ns = 5\n",
    "    else:\n",
    "        total_ns = 20\n",
    "    cumulative_data_row = {\n",
    "        \"partner\": row[\"partner_id\"],\n",
    "        \"system name\": row[\"dataset_name\"],\n",
    "        \"ligand_A\": row[\"ligand_A\"],\n",
    "        \"ligand_B\": row[\"ligand_B\"],\n",
    "        \"exp DDG (kcal/mol)\": row[\"exp DDG (kcal/mol)\"],\n",
    "        \"exp dDDG (kcal/mol)\": row[\"exp dDDG (kcal/mol)\"],\n",
    "        \"alchemical_charge_difference\": row[\"alchemical_charge_difference\"]\n",
    "    }\n",
    "    # workout the estimate of DDG for each ns\n",
    "    temp_cumulative_data = private_cumulative_data[(private_cumulative_data[\"partner_id\"] == row[\"partner_id\"]) & (private_cumulative_data[\"dataset_name\"] == row[\"dataset_name\"])].copy(deep=True).reset_index(drop=True)\n",
    "    complex_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"complex\")]\n",
    "    solvent_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"solvent\")]\n",
    "\n",
    "    for i in range(1, total_ns + 1):\n",
    "        # print(complex_data[f\"Samples {i}ns (subsample) DG\"])\n",
    "        per_ns_complex = complex_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_complex_error = complex_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        per_ns_solvent = solvent_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_solvent_error = solvent_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        cumulative_data_row[f\"Samples {i} ns DDG\"] = per_ns_complex - per_ns_solvent\n",
    "        cumulative_data_row[f\"Samples {i} ns dDDG\"] = (per_ns_complex_error ** 2 + per_ns_solvent_error ** 2) ** 0.5\n",
    "    # workout where to store the row\n",
    "    if total_ns == 5:\n",
    "        per_ns_ddgs_neutral_private.append(cumulative_data_row)\n",
    "    else:\n",
    "        per_ns_ddgs_charged_private.append(cumulative_data_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average uncertainty for the public and private data for the neutral edges\n",
    "per_ns_ddgs_neutral = pd.DataFrame(per_ns_ddgs_neutral)\n",
    "per_ns_ddgs_neutral[\"Samples 5 ns dDDG\"].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ns_ddgs_neutral_private = pd.DataFrame(per_ns_ddgs_neutral_private)\n",
    "per_ns_ddgs_neutral_private[\"Samples 5 ns dDDG\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ns_ddgs_neutral_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason the estimate at 5ns is different for edge 27-6 in shp2 but all others are the same\n",
    "# so we patch the value\n",
    "# calculate the value for the 5 ns DDG\n",
    "shp2_edge = normal_edge_data.loc[\n",
    "    (normal_edge_data[\"system group\"] == \"merck\") & \n",
    "    (normal_edge_data[\"system name\"] == \"shp2\") & \n",
    "    (normal_edge_data[\"ligand_A\"] == \"Example-27\") & \n",
    "    (normal_edge_data[\"ligand_B\"] == \"6\")\n",
    "]\n",
    "complex_data = shp2_edge[[f\"complex_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "solvent_data = shp2_edge[[f\"solvent_repeat_{i}_DG (kcal/mol)\" for i in range(3)]]\n",
    "# calculate the 5 ns DDG and dDDG\n",
    "ddg_5_ns = complex_data.mean(axis=1) - solvent_data.mean(axis=1)\n",
    "ddg_5_ns_error = (complex_data.std(axis=1) ** 2 + solvent_data.std(axis=1) ** 2) ** 0.5\n",
    "per_ns_ddgs_neutral.loc[\n",
    "    (per_ns_ddgs_neutral[\"system group\"] == \"merck\") & \n",
    "    (per_ns_ddgs_neutral[\"system name\"] == \"shp2\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_A\"] == \"Example-27\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_B\"] == \"6\"), \n",
    "    \"Samples 5 ns DDG\"\n",
    "] = ddg_5_ns.values[0]\n",
    "per_ns_ddgs_neutral.loc[\n",
    "    (per_ns_ddgs_neutral[\"system group\"] == \"merck\") & \n",
    "    (per_ns_ddgs_neutral[\"system name\"] == \"shp2\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_A\"] == \"Example-27\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_B\"] == \"6\"), \n",
    "    \"Samples 5 ns dDDG\"\n",
    "] = ddg_5_ns_error.values[0]\n",
    "# print the updated row \n",
    "print(per_ns_ddgs_neutral.loc[\n",
    "    (per_ns_ddgs_neutral[\"system group\"] == \"merck\") & \n",
    "    (per_ns_ddgs_neutral[\"system name\"] == \"shp2\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_A\"] == \"Example-27\") & \n",
    "    (per_ns_ddgs_neutral[\"ligand_B\"] == \"6\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_dg_data.rename(columns={\n",
    "    \"dataset_name\": \"system name\",\n",
    "    \"partner_id\": \"partner\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinnabar import FEMap, Measurement\n",
    "from openff.units import unit\n",
    "from collections import defaultdict\n",
    "from scipy.stats import kendalltau\n",
    "def get_metric_per_ns(df_neutral, df_charged, dg_df, public=True) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculate the DG values for each 20% of the simulation time, calculate the standard bootstrapped statistics and the pairwise RMSE and MUE DDG values.\n",
    "    \"\"\"\n",
    "    if public:\n",
    "        system_group_col = \"system group\"\n",
    "        system_name_col = \"system name\"\n",
    "    else:\n",
    "        system_group_col = \"partner\"\n",
    "        system_name_col = \"system name\"\n",
    "    # merge the neutral and charged dataframes\n",
    "    temp_df = pd.concat([df_neutral, df_charged], ignore_index=True)\n",
    "    all_data = []\n",
    "    all_pairwise_data = defaultdict(list)\n",
    "    for system in temp_df[system_group_col].unique():\n",
    "        system_df = temp_df[temp_df[system_group_col] == system].copy(deep=True).reset_index(drop=True)\n",
    "        targets = system_df[system_name_col].unique()\n",
    "        for target in targets:\n",
    "            target_df = system_df[system_df[system_name_col] == target].copy(deep=True).reset_index(drop=True)\n",
    "            # get the experimental values for this target\n",
    "            exp_dg = dg_df[(dg_df[system_name_col] == target) & (dg_df[system_group_col] == system) & (dg_df[\"Exp DG (kcal/mol)\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "            exp_shift = exp_dg[\"Exp DG (kcal/mol)\"].mean()\n",
    "            for t in range(20, 120, 20):\n",
    "                print(f\"Calculating for {system} {target} at {t}%\")\n",
    "                fe_map = FEMap()\n",
    "                for _, row in target_df.iterrows():\n",
    "                    # workout the total sampling time\n",
    "                    total_ns = 5 if row[\"alchemical_charge_difference\"] == 0 else 20\n",
    "                    # workout the number of ns to use\n",
    "                    ns = int(total_ns * (t / 100))\n",
    "                    # get the ddg and uncertainty for this ns\n",
    "                    ddg = row[f\"Samples {int(ns)} ns DDG\"]\n",
    "                    ddg_uncertainty = row[f\"Samples {int(ns)} ns dDDG\"]\n",
    "                    # add the measurement to the fe map\n",
    "                    fe_map.add_relative_calculation(\n",
    "                        labelA=row[\"ligand_A\"],\n",
    "                        labelB=row[\"ligand_B\"],\n",
    "                        value=ddg * unit.kilocalorie_per_mole,\n",
    "                        uncertainty=ddg_uncertainty * unit.kilocalorie_per_mole if ddg_uncertainty != 0 else 0.1 * unit.kilocalorie_per_mole,\n",
    "                    )\n",
    "                try:\n",
    "                    fe_map.generate_absolute_values()\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error generating absolute values for {system} {target} at {t}%: {e}\")\n",
    "                    continue\n",
    "                abs_df = fe_map.get_absolute_dataframe()\n",
    "                # nake an array of the exp data in the same order as the predicted values\n",
    "                exp_values, calculated_values = [], []\n",
    "                for _, abs_row in abs_df.iterrows():\n",
    "                    try:\n",
    "                        exp_value = exp_dg[exp_dg[\"ligand name\"] == abs_row[\"label\"]][\"Exp DG (kcal/mol)\"].values[0]\n",
    "                        exp_values.append(exp_value - exp_shift)\n",
    "                        calculated_values.append(abs_row[\"DG (kcal/mol)\"])\n",
    "                    except IndexError:\n",
    "                        # merck-syk has intermediate ligands that are not in the exp data so skip them\n",
    "                        continue\n",
    "                # calculate the stats \n",
    "                # mark if we have a Hahn system number of ligands above 16 and dynamic range >= 3 kca/mol\n",
    "                ns_data = {\n",
    "                    \"system group\": system,\n",
    "                    \"system name\": target,\n",
    "                    \"Sampling ns\": t,    \n",
    "                    \"Number of ligands\": len(exp_values),\n",
    "                }\n",
    "                if len(exp_values) > 16 and (exp_dg[\"Exp DG (kcal/mol)\"].max() - exp_dg[\"Exp DG (kcal/mol)\"].min()) >= 3:\n",
    "                    ns_data[\"Hahn system\"] = True\n",
    "                else:\n",
    "                    ns_data[\"Hahn system\"] = False\n",
    "                boot_mue, boot_rmse, boot_ktau = np.zeros(1000), np.zeros(1000), np.zeros(1000)\n",
    "                exp_values = np.array(exp_values)\n",
    "                calculated_values = np.array(calculated_values)\n",
    "                for i in range(1000):\n",
    "                    # bootstrap the predictions and exp values\n",
    "                    boot_indices = np.random.choice(len(exp_values), size=len(exp_values), replace=True)\n",
    "                    boot_exp_values = exp_values[boot_indices]\n",
    "                    boot_calc_values = calculated_values[boot_indices]\n",
    "                    boot_mue[i] = np.mean(np.abs(boot_calc_values - boot_exp_values))\n",
    "                    boot_rmse[i] = np.sqrt(np.mean((boot_calc_values - boot_exp_values) ** 2))\n",
    "                    boot_ktau[i] = kendalltau(boot_calc_values, boot_exp_values)[0]\n",
    "                    \n",
    "                for stat, values in zip(\n",
    "                    [\"MUE\", \"RMSE\", \"Kendall Tau\"],\n",
    "                    [boot_mue, boot_rmse, boot_ktau]\n",
    "                ):\n",
    "                    ns_data[stat] = np.mean(values)\n",
    "                    ns_data[f\"{stat} lower\"] = np.percentile(values, 2.5)\n",
    "                    ns_data[f\"{stat} higher\"] = np.percentile(values, 97.5)\n",
    "\n",
    "                # calculate the all pairwise RMSE\n",
    "                pairwise_predictions, pairwise_exp = [], []\n",
    "                ligands = abs_df[\"label\"].unique()\n",
    "                for i, ligand1 in enumerate(ligands):\n",
    "                    for j, ligand2 in enumerate(ligands):\n",
    "                        if i >= j:\n",
    "                            # skip self-comparisons\n",
    "                            continue\n",
    "                        lig_1_value = abs_df[abs_df[\"label\"] == ligand1][\"DG (kcal/mol)\"].values[0]\n",
    "                        lig_2_value = abs_df[abs_df[\"label\"] == ligand2][\"DG (kcal/mol)\"].values[0]\n",
    "                        # these values are in the same order as the abs_df\n",
    "                        try:\n",
    "                            lig_1_exp = exp_dg[exp_dg[\"ligand name\"] == ligand1][\"Exp DG (kcal/mol)\"].values[0] - exp_shift\n",
    "                            lig_2_exp = exp_dg[exp_dg[\"ligand name\"] == ligand2][\"Exp DG (kcal/mol)\"].values[0] - exp_shift\n",
    "                            # transforming I->j is J - I\n",
    "                            pairwise_exp.append(lig_2_exp - lig_1_exp)\n",
    "                            pairwise_predictions.append(lig_2_value - lig_1_value)\n",
    "                        except IndexError:\n",
    "                            # skip if we have an intermediate ligand that is not in the exp data\n",
    "                            print(f\"Skipping pairwise comparison for {ligand1} and {ligand2} in {system} {target} at {t}% due to missing experimental data.\")\n",
    "                            continue\n",
    "                # calculate the pairwise stats\n",
    "                # add the absolute pairwise error data\n",
    "                all_pairwise_data[t].extend(abs(np.array(pairwise_predictions) - np.array(pairwise_exp)))\n",
    "                pairwise_rmse = np.zeros(1000)\n",
    "                for i in range(1000):\n",
    "                    # bootstrap the pairwise predictions and exp values\n",
    "                    boot_indices = np.random.choice(len(pairwise_exp), size=len(pairwise_exp), replace=True)\n",
    "                    boot_pairwise_predictions = np.array(pairwise_predictions)[boot_indices]\n",
    "                    boot_pairwise_exp = np.array(pairwise_exp)[boot_indices]\n",
    "                    pairwise_rmse[i] = np.sqrt(np.mean((boot_pairwise_predictions - boot_pairwise_exp) ** 2))\n",
    "\n",
    "                ns_data[f\"Pairwise RMSE\"] = np.mean(pairwise_rmse)\n",
    "                ns_data[f\"Pairwise RMSE lower\"] = np.percentile(pairwise_rmse, 2.5)\n",
    "                ns_data[f\"Pairwise RMSE higher\"] = np.percentile(pairwise_rmse, 97.5)\n",
    "                all_data.append(ns_data)\n",
    "    return pd.DataFrame(all_data), all_pairwise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_public, pairwise_public = get_metric_per_ns(pd.DataFrame(per_ns_ddgs_neutral), pd.DataFrame(per_ns_ddgs_charged), public_dg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_private, pairwise_private = get_metric_per_ns(pd.DataFrame(per_ns_ddgs_neutral_private), pd.DataFrame(per_ns_ddgs_charged_private), private_dg_data, public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_public.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ecdf for each 20% of the simulation time for the pairwise data\n",
    "# make the figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for t, pairwise_data in pairwise_public.items():\n",
    "    sns.ecdfplot(\n",
    "        pairwise_data,\n",
    "        ax=ax,\n",
    "        label=f\"{t}%\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    sns.ecdfplot(\n",
    "        pairwise_private[t],\n",
    "        ax=ax,\n",
    "        label=f\"{t}% (private)\",\n",
    "        linewidth=2,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "ax.set_xlabel(r\"Pairwise |$\\Delta\\Delta$G$_{calc} - \\Delta\\Delta$G$_{exp}$ | (kcal/mol)\", fontsize=14)\n",
    "ax.set_ylabel(\"Cumulative Probability\", fontsize=14)\n",
    "plt.legend(title=\"Simulation Time\", fontsize=12)\n",
    "# set tick fontsize\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.xlim(0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metrics_public[metrics_public[\"Sampling ns\"] == 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_private[metrics_private[\"system group\"] == \"Roche\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot to compare KTAU for each 20% of the simulation time\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "sns.boxplot(\n",
    "    x=\"Sampling ns\",\n",
    "    y=\"RMSE\",\n",
    "    data=metrics_public,\n",
    "    ax=ax[0],\n",
    "    label=\"Public\",\n",
    ")\n",
    "sns.boxplot(\n",
    "    x=\"Sampling ns\",\n",
    "    y=\"RMSE\",\n",
    "    data=metrics_private,\n",
    "    ax=ax[1],\n",
    "    label=\"Private\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "# check for significant differences between the 80 and 100% sampling time using a wilcoxon test\n",
    "from scipy.stats import wilcoxon\n",
    "for i, d in enumerate([metrics_public, metrics_private]):\n",
    "    dh = 0.1\n",
    "    y_max = 0\n",
    "    rx = 4\n",
    "    for lx, j in enumerate([20, 40, 60, 80]):\n",
    "        # get the rmse for each sampling time\n",
    "        sample_rmse = d[d[\"Sampling ns\"] == j]\n",
    "        full_rmse = []\n",
    "        # some MLE estimates failed for low sampling times so filter them out\n",
    "        for _, row in sample_rmse.iterrows():\n",
    "            full_rmse.append(d[(d[\"system group\"] == row[\"system group\"]) & (d[\"system name\"] == row[\"system name\"]) & (d[\"Sampling ns\"] == 100)][\"RMSE\"].values[0])\n",
    "\n",
    "        # test the difference between the full and sample rmse\n",
    "        stat, p_value = wilcoxon(full_rmse, sample_rmse[\"RMSE\"].values)\n",
    "\n",
    "        print(f\"Wilcoxon test between {j}% and 100% sampling time: stat={stat}, p-value={p_value}\")\n",
    "        # if there is a significant difference show it on the plot \n",
    "        if p_value < 0.05:\n",
    "            y_max = max(max(full_rmse), sample_rmse[\"RMSE\"].values.max(), y_max) + dh\n",
    "            barx = [lx, lx, rx, rx]\n",
    "            bary = [y_max, y_max + 0.05, y_max + 0.05, y_max]\n",
    "            ax[i].plot(barx, bary, color=\"black\", linewidth=1.5)\n",
    "            p = .05\n",
    "            text = \"\"\n",
    "            while p_value < p:\n",
    "                text += \"*\"\n",
    "                p *= 0.1\n",
    "\n",
    "            ax[i].text((lx + rx) / 2, y_max + 0.05, f\"{text}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "            y_max += 0.1\n",
    "\n",
    "fig.legend(title=\"Dataset\", fontsize=10, ncol=2, loc=\"upper center\", bbox_to_anchor=(0.5, 1.0), frameon=True, title_fontsize=14)\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot to compare KTAU for each 20% of the simulation time\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "hahn_public = metrics_public[metrics_public[\"Hahn system\"] == True]\n",
    "hahn_private = metrics_private[metrics_private[\"Hahn system\"] == True]\n",
    "sns.boxplot(\n",
    "    x=\"Sampling ns\",\n",
    "    y=\"Kendall Tau\",\n",
    "    data=hahn_public,\n",
    "    ax=ax[0],\n",
    "    label=\"Public\",\n",
    ")\n",
    "sns.boxplot(\n",
    "    x=\"Sampling ns\",\n",
    "    y=\"Kendall Tau\",\n",
    "    data=hahn_private,\n",
    "    ax=ax[1],\n",
    "    label=\"Private\",\n",
    "    color=\"orange\",)\n",
    "\n",
    "for i, d in enumerate([hahn_public, hahn_private]):\n",
    "    dh = 0.1\n",
    "    y_max = 0\n",
    "    rx = 4\n",
    "    for lx, j in enumerate([20, 40, 60, 80]):\n",
    "        # get the rmse for each sampling time\n",
    "        sample_rmse = d[d[\"Sampling ns\"] == j]\n",
    "        full_rmse = []\n",
    "        # some MLE estimates failed for low sampling times so filter them out\n",
    "        for _, row in sample_rmse.iterrows():\n",
    "            full_rmse.append(d[(d[\"system group\"] == row[\"system group\"]) & (d[\"system name\"] == row[\"system name\"]) & (d[\"Sampling ns\"] == 100)][\"Kendall Tau\"].values[0])\n",
    "\n",
    "        # test the difference between the full and sample rmse\n",
    "        stat, p_value = wilcoxon(full_rmse, sample_rmse[\"Kendall Tau\"].values)\n",
    "\n",
    "        print(f\"Wilcoxon test between {j}% and 100% sampling time: stat={stat}, p-value={p_value}\")\n",
    "        # if there is a significant difference show it on the plot \n",
    "        if p_value < 0.05:\n",
    "            y_max = max(max(full_rmse), sample_rmse[\"Kendall Tau\"].values.max(), y_max) + dh\n",
    "            barx = [lx, lx, rx, rx]\n",
    "            bary = [y_max, y_max + 0.05, y_max + 0.05, y_max]\n",
    "            ax[i].plot(barx, bary, color=\"black\", linewidth=1.5)\n",
    "            p = .05\n",
    "            text = \"\"\n",
    "            while p_value < p:\n",
    "                text += \"*\"\n",
    "                p *= 0.1\n",
    "\n",
    "            ax[i].text((lx + rx) / 2, y_max + 0.05, f\"{text}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "            y_max += 0.1\n",
    "\n",
    "fig.legend(title=\"Dataset\", fontsize=10, ncol=2, loc=\"upper center\", bbox_to_anchor=(0.5, 1.0), frameon=True, title_fontsize=14)\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].get_legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for system in metrics_public[\"system group\"].unique():\n",
    "    system_df = metrics_public[metrics_public[\"system group\"] == system]\n",
    "    targets = system_df[\"system name\"].unique()\n",
    "    for target in targets:\n",
    "        target_df = system_df[system_df[\"system name\"] == target]\n",
    "        rmses = []\n",
    "        for t in [20, 40, 60, 80, 100]:\n",
    "            rmses.append(target_df[target_df[\"Sampling ns\"] == t][\"RMSE\"].values[0])\n",
    "        # find system where the RMSE fluctuates a lot between 20 and 100%\n",
    "        if abs(rmses[2] - rmses[-1]) > 0.3:\n",
    "            print(f\"{system} {target} has a large fluctuation in RMSE between 20 and 100%: {rmses}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again for the private data\n",
    "for system in metrics_private[\"system group\"].unique():\n",
    "    if system == \"Odyssey\":\n",
    "        # skip the Odyssey system as it has a different sampling time\n",
    "        continue\n",
    "    system_df = metrics_private[metrics_private[\"system group\"] == system]\n",
    "    targets = system_df[\"system name\"].unique()\n",
    "    for target in targets:\n",
    "        target_df = system_df[system_df[\"system name\"] == target]\n",
    "        rmses = []\n",
    "        for t in [20, 40, 60, 80, 100]:\n",
    "            print(target_df[target_df[\"Sampling ns\"] == t])\n",
    "            rmses.append(target_df[target_df[\"Sampling ns\"] == t][\"RMSE\"].values[0])\n",
    "        # find system where the RMSE fluctuates a lot between 20 and 100%\n",
    "        if abs(rmses[2] - rmses[-1]) > 0.5:\n",
    "            print(f\"{system} {target} has a large fluctuation in RMSE between 20 and 100%: {rmses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the public and private data together\n",
    "# make the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "# calculate the mean change between x and x+1 with 95% CI\n",
    "nbootstrap = 1000\n",
    "ci = 0.95\n",
    "\n",
    "colors = sns.color_palette(\"rocket\", 4)\n",
    "c = 0\n",
    "for dataset, ns_range, label, line in zip([pd.DataFrame(per_ns_ddgs_neutral), pd.DataFrame(per_ns_ddgs_charged), pd.DataFrame(per_ns_ddgs_neutral_private), pd.DataFrame(per_ns_ddgs_charged_private)],\n",
    "                                           [5, 20, 5, 20],\n",
    "                                           [\"Public Neutral\", \"Public Charged\", \"Private Neutral\", \"Private Charged\"],\n",
    "                                           [\"-\", \"-\", \"--\", \"--\"]):\n",
    "\n",
    "    # calculate the mean change between x and x+1 with 95% CI\n",
    "    changes_in_ddg = []\n",
    "    # get the final value using all simulation data\n",
    "    for i in range(1, ns_range + 1):\n",
    "        # get the DDG values for I sampling time\n",
    "        temp_df = dataset[(dataset[f\"Samples {i} ns DDG\"].notna()) & (dataset[f\"Samples {ns_range} ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "        # get the difference between this ns and the final value using all data\n",
    "        change_in_ddg = abs(temp_df[f\"Samples {i} ns DDG\"] - temp_df[f\"Samples {ns_range} ns DDG\"])\n",
    "        print(i, change_in_ddg.mean())\n",
    "\n",
    "        mean_change = change_in_ddg.mean()\n",
    "        # get the bootstrap CI\n",
    "        mean_values = np.zeros(nbootstrap)\n",
    "        for i in range(nbootstrap):\n",
    "            sample_ids = np.random.choice(len(change_in_ddg), size=len(change_in_ddg), replace=True)\n",
    "            sample_data = change_in_ddg[sample_ids]\n",
    "            mean_values[i] = sample_data.mean()\n",
    "        # get the 95% CI\n",
    "        low = np.percentile(mean_values, 2.5)\n",
    "        high = np.percentile(mean_values, 97.5)\n",
    "        change_stats = {\n",
    "            \"mean change\": mean_change,\n",
    "            \"extra ns\": i,\n",
    "            \"low\": low,\n",
    "            \"high\": high\n",
    "        }\n",
    "\n",
    "        changes_in_ddg.append(change_stats)\n",
    "    temp_change_df = pd.DataFrame(changes_in_ddg)\n",
    "    print(temp_change_df)\n",
    "    x_labels = [100 * (i / ns_range) for i in range(1, ns_range + 1)]\n",
    "    plt.plot(x_labels, temp_change_df[\"mean change\"], label=label, linestyle=line, color=colors[c])\n",
    "    plt.fill_between(x_labels, temp_change_df[\"low\"], temp_change_df[\"high\"], alpha=0.2, linestyle=line, color=colors[c])\n",
    "    c += 1\n",
    "plt.ylim((0, 1))\n",
    "plt.xlim((0, 100))\n",
    "plt.legend(labelspacing=0.1, fontsize=12)\n",
    "plt.xlabel(\"Sampling %\", fontdict={\"fontsize\": 12})\n",
    "plt.ylabel(r\"$<|\\Delta\\Delta G_{N} - \\Delta\\Delta G_{total}|>$ kcal/mol\", fontdict={\"fontsize\": 12})\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig(\"distance_to_final_ddg_percent_public_private.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_private = pd.DataFrame(per_ns_ddgs_neutral_private)\n",
    "neutral_private = neutral_private[(neutral_private[\"Samples 5 ns DDG\"].notna()) & (neutral_private[\"Samples 1 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "change_in_private = abs(neutral_private[\"Samples 1 ns DDG\"] - neutral_private[\"Samples 5 ns DDG\"])\n",
    "change_in_private.mean(), change_in_private.std()\n",
    "neutral_private[\"Samples 5 ns dDDG\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_the_distance_to_final_ddg(dataset, ns_range, name):\n",
    "\n",
    "    # get the final value using all simulation data\n",
    "    for i in range(1, ns_range):\n",
    "        # get the DDG values for I sampling time\n",
    "        temp_df = dataset[(dataset[f\"Samples {i} ns DDG\"].notna()) & (dataset[f\"Samples {ns_range} ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "        # get the difference between this ns and the final value using all data\n",
    "        change_in_ddg = abs(temp_df[f\"Samples {i} ns DDG\"] - temp_df[f\"Samples {ns_range} ns DDG\"])\n",
    "        print(i, change_in_ddg.mean())\n",
    "\n",
    "        sns.ecdfplot(x=change_in_ddg, label=f\"{i} ns\", linewidth=2)\n",
    "        # plot the mean uncertainty at the full simulation length as a vertical line\n",
    "    plt.axvline(x=dataset[f\"Samples {ns_range} ns dDDG\"].mean(), color=\"k\", linestyle='--', label=f\"Average uncertainty at {ns_range} ns\")\n",
    "       \n",
    "    plt.legend(labelspacing=0.1, fontsize=12)\n",
    "    plt.ylabel(\"Proportion\", fontdict={\"fontsize\": 12})\n",
    "    plt.xlabel(r\"$|\\Delta\\Delta G_{N} - \\Delta\\Delta G_{total}|$ kcal/mol\", fontdict={\"fontsize\": 12})\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.savefig(name, dpi=300, bbox_inches=\"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_distance_to_final_ddg(dataset=pd.DataFrame(per_ns_ddgs_neutral), ns_range=5, name=\"distance_to_final_ddg_neutral_public.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_distance_to_final_ddg(dataset=pd.DataFrame(per_ns_ddgs_neutral_private), ns_range=5, name=\"distance_to_final_ddg_neutral_private.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_distance_to_final_ddg(dataset=pd.DataFrame(per_ns_ddgs_charged), ns_range=20, name=\"distance_to_final_ddg_charged_public.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_distance_to_final_ddg(dataset=pd.DataFrame(per_ns_ddgs_charged_private), ns_range=20, name=\"distance_to_final_ddg_charged_private.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of neutral edges at 4ns with a distance lower than the average uncertainty at 5ns\n",
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral_private)\n",
    "neutral_df = neutral_df[(neutral_df[\"Samples 5 ns DDG\"].notna()) & (neutral_df[\"Samples 4 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# get the abs error\n",
    "abs_diff = abs(neutral_df[\"Samples 4 ns DDG\"] - neutral_df[\"Samples 5 ns DDG\"])\n",
    "no_edges = neutral_df[abs_diff < neutral_df[\"Samples 5 ns dDDG\"].mean()][\"Samples 4 ns DDG\"].count()\n",
    "no_edges / len(neutral_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again for the charged edges\n",
    "charged_df = pd.DataFrame(per_ns_ddgs_charged)\n",
    "charged_df = charged_df[(charged_df[\"Samples 20 ns DDG\"].notna()) & (charged_df[\"Samples 16 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# get the abs error\n",
    "abs_diff = abs(charged_df[\"Samples 16 ns DDG\"] - charged_df[\"Samples 20 ns DDG\"])\n",
    "no_edges = charged_df[abs_diff < charged_df[\"Samples 20 ns dDDG\"].mean()][\"Samples 16 ns DDG\"].count()\n",
    "no_edges / len(charged_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_df[\"Samples 20 ns dDDG\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# calculate the wilcoxon test for the neutral edges comparing the difference after 4 ns and 5ns\n",
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral)\n",
    "neutral_df = neutral_df[(neutral_df[\"Samples 5 ns DDG\"].notna()) & (neutral_df[\"Samples 4 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# calculate the signed difference\n",
    "diff = neutral_df[\"Samples 5 ns DDG\"] - neutral_df[\"Samples 4 ns DDG\"]\n",
    "# calculate the wilcoxon test\n",
    "w, p = wilcoxon(diff)\n",
    "print(f\"Wilcoxon test: {w}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the wilcoxon test for the charged edges comparing the difference after 16 ns and 20ns\n",
    "charged_df = pd.DataFrame(per_ns_ddgs_charged_private)\n",
    "charged_df = charged_df[(charged_df[\"Samples 20 ns DDG\"].notna()) & (charged_df[\"Samples 16 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# calculate the signed difference\n",
    "diff = charged_df[\"Samples 16 ns DDG\"] - charged_df[\"Samples 20 ns DDG\"]\n",
    "# calculate the wilcoxon test\n",
    "w, p = wilcoxon(diff)\n",
    "print(f\"Wilcoxon test: {w}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the bootstrap confidence interval for the difference between 4 ns and 5 ns\n",
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral)\n",
    "diffs = neutral_df[\"Samples 4 ns DDG\"] - neutral_df[\"Samples 5 ns DDG\"]\n",
    "n_bootstrap = 1000\n",
    "boot_diffs = []\n",
    "n_edges = len(diffs)\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    sample = np.random.choice(diffs, size=n_edges, replace=True)\n",
    "    boot_diffs.append(np.mean(sample))\n",
    "\n",
    "ci_lower = np.percentile(boot_diffs, 2.5)\n",
    "ci_upper = np.percentile(boot_diffs, 97.5)\n",
    "mean_diff = np.mean(diffs)\n",
    "# Plot: 4 ns vs 5 ns predictions and difference histogram\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Scatter plot of predictions\n",
    "axs[0].scatter(neutral_df[\"Samples 5 ns DDG\"], neutral_df[\"Samples 4 ns DDG\"], color='#009384', edgecolor='k')\n",
    "axs[0].plot([-15, 20], [-15, 20], 'k--', label='y = x')\n",
    "axs[0].set_xlabel('∆∆G at 5 ns (kcal/mol)', fontdict={\"fontsize\": 12})\n",
    "axs[0].set_ylabel('∆∆G at 4 ns (kcal/mol)', fontdict={\"fontsize\": 12})\n",
    "# set the size of the xticks on the x axis\n",
    "axs[0].tick_params(axis='x', labelsize=12)\n",
    "# same for the y axis\n",
    "axs[0].tick_params(axis='y', labelsize=12)\n",
    "# axs[0].xticks(fontsize=12)\n",
    "axs[0].set_title('Comparison of Predictions at 4 ns vs 5 ns')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "# plt.xticks(fontsize=12)\n",
    "\n",
    "# Histogram of differences\n",
    "sns.histplot(diffs, bins=15, kde=True, ax=axs[1], color='#009384')\n",
    "axs[1].axvline(ci_lower, color='red', linestyle='--', label=f\"95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "axs[1].axvline(ci_upper, color='red', linestyle='--')\n",
    "axs[1].axvline(mean_diff, color='black', linestyle='-', label=f\"Mean diff: {mean_diff:.3f}\")\n",
    "axs[1].set_xlabel('∆∆G (4 ns - 5 ns)', fontdict={\"fontsize\": 12})\n",
    "axs[1].set_ylabel('Frequency', fontdict={\"fontsize\": 12})\n",
    "axs[1].set_title('Distribution of Prediction Differences')\n",
    "axs[1].tick_params(axis='x', labelsize=12)\n",
    "# same for the y axis\n",
    "axs[1].tick_params(axis='y', labelsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"4ns_vs_5ns_public.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the charged data\n",
    "# calculate the bootstrap confidence interval for the difference between 16 ns and 20 ns\n",
    "diffs = charged_df[\"Samples 15 ns DDG\"] - charged_df[\"Samples 20 ns DDG\"]\n",
    "n_bootstrap = 1000\n",
    "boot_diffs = []\n",
    "n_edges = len(diffs)\n",
    "for _ in range(n_bootstrap):\n",
    "    sample = np.random.choice(diffs, size=n_edges, replace=True)\n",
    "    boot_diffs.append(np.mean(sample))\n",
    "ci_lower = np.percentile(boot_diffs, 2.5)\n",
    "ci_upper = np.percentile(boot_diffs, 97.5)\n",
    "mean_diff = np.mean(diffs)\n",
    "# Plot: 16 ns vs 20 ns predictions and difference histogram\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Scatter plot of predictions\n",
    "axs[0].scatter(charged_df[\"Samples 20 ns DDG\"], charged_df[\"Samples 15 ns DDG\"], color='#009384', edgecolor='k')\n",
    "axs[0].plot([-5, 5], [-5, 5], 'k--', label='y = x')\n",
    "axs[0].set_xlabel('∆∆G at 20 ns (kcal/mol)', fontdict={\"fontsize\": 12})\n",
    "axs[0].set_ylabel('∆∆G at 15 ns (kcal/mol)', fontdict={\"fontsize\": 12})\n",
    "# set the size of the xticks on the x axis\n",
    "axs[0].tick_params(axis='x', labelsize=12)\n",
    "# same for the y axis\n",
    "axs[0].tick_params(axis='y', labelsize=12)\n",
    "axs[0].set_title('Comparison of Predictions at 15 ns vs 20 ns')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "# plt.xticks(fontsize=12)\n",
    "# Histogram of differences\n",
    "sns.histplot(diffs, bins=15, kde=True, ax=axs[1], color='#009384')\n",
    "axs[1].axvline(ci_lower, color='red', linestyle='--', label=f\"95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "axs[1].axvline(ci_upper, color='red', linestyle='--')\n",
    "axs[1].axvline(mean_diff, color='black', linestyle='-', label=f\"Mean diff: {mean_diff:.3f}\")\n",
    "axs[1].set_xlabel('∆∆G (15 ns - 20 ns)', fontdict={\"fontsize\": 12})\n",
    "axs[1].set_ylabel('Frequency', fontdict={\"fontsize\": 12})\n",
    "axs[1].set_title('Distribution of Prediction Differences')\n",
    "axs[1].tick_params(axis='x', labelsize=12)\n",
    "# same for the y axis\n",
    "axs[1].tick_params(axis='y', labelsize=12)\n",
    "axs[1].legend(fontsize=12)\n",
    "axs[1].grid(True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"15ns_vs_20ns_charged.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all of the molecules\n",
    "# load all the ligands\n",
    "import pathlib\n",
    "from rdkit import Chem\n",
    "all_ligands = {}\n",
    "name_conversions = {\n",
    "    \"41 flip\": \"41-flip\",\n",
    "    \"40 flip\": \"40-flip\",\n",
    "    \"38 flip\": \"38-flip\",\n",
    "    \"30 flip\": \"30-flip\",\n",
    "    \"43 flip\": \"43-flip\",\n",
    "    \"47 flip\": \"47-flip\",\n",
    "    \"48 flip\": \"48-flip\",\n",
    "    \"46 flip\": \"46-flip\",\n",
    "    \"36 out\": \"36o\",\n",
    "    \"37 out\": \"37o\",\n",
    "    \"38 out\": \"38o\",\n",
    "    \"39 out\": \"39o\",\n",
    "    \"28 out\": \"28o\",\n",
    "    \"CHEMBL3402756_2.7 redocked\": \"CHEMBL3402756_2.7_redocked\",\n",
    "    \"CHEMBL3402757_6.5 redocked\" : \"CHEMBL3402757_6.5_redocked\",\n",
    "    \"CHEMBL3402758_10 redocked\": \"CHEMBL3402758_10_redocked\",\n",
    "    \"CHEMBL3402760_1 redocked\":\"CHEMBL3402760_1_redocked\",\n",
    "    \"CHEMBL3402762_1 redocked\": \"CHEMBL3402762_1_redocked\",\n",
    "    \"CHEMBL3402759_5.7 redocked\": \"CHEMBL3402759_5.7_redocked\",\n",
    "    \"CHEMBL3402761_1 redocked\": \"CHEMBL3402761_1_redocked\",\n",
    "    \"Example 22\":\"Example-22\",\n",
    "    \"Example 23\": \"Example-23\",\n",
    "    \"Example 14\": \"Example-14\",\n",
    "    \"Example 9\": \"Example-9\",\n",
    "    \"SHP099-1 Example 7\": \"SHP099-1-Example-7\",\n",
    "    \"Example 28\": \"Example-28\",\n",
    "    \"Example 24\": \"Example-24\",\n",
    "    \"Example 26\": \"Example-26\",\n",
    "    \"Example 6\": \"Example-6\",\n",
    "    \"Example 1\": \"Example-1\",\n",
    "    \"Example 30\": \"Example-30\",\n",
    "    \"Example 8\": \"Example-8\",\n",
    "    \"Example 29\": \"Example-29\",\n",
    "    \"Example 2\": \"Example-2\",\n",
    "    \"Example 25\": \"Example-25\",\n",
    "    \"Example 4\": \"Example-4\",\n",
    "    \"Example 3\": \"Example-3\",\n",
    "    \"Example 27\": \"Example-27\",\n",
    "    \"Example 5\": \"Example-5\",\n",
    "    \"9 flip\": \"9-flip\",\n",
    "}\n",
    "key_to_ligand = {}\n",
    "base_data_folder = pathlib.Path(\"/Users/joshua/Documents/Software/IndustryBenchmarks2024/industry_benchmarks/input_structures/prepared_structures\")\n",
    "for folder in base_data_folder.glob(\"*\"):\n",
    "    if folder.is_dir() and folder != \"template\":\n",
    "        for target_ligs in folder.glob(\"*/ligands.sdf\"):\n",
    "            # load the ligands\n",
    "            supplier = Chem.SDMolSupplier(target_ligs, removeHs=False)\n",
    "            for lig in supplier:\n",
    "                name = lig.GetProp(\"_Name\")\n",
    "                if name in name_conversions:\n",
    "                    name = name_conversions[name]\n",
    "                all_ligands[(name, target_ligs.parent.name, folder.name)] = Chem.GetFormalCharge(lig)\n",
    "                key_to_ligand[(name, target_ligs.parent.name, folder.name)] = lig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gufe import SmallMoleculeComponent\n",
    "import kartograf\n",
    "from kartograf.filters import (\n",
    "    filter_ringbreak_changes,\n",
    "    filter_ringsize_changes,\n",
    "    filter_whole_rings_only,\n",
    ")\n",
    "from rdkit.Chem import Draw\n",
    "import io\n",
    "import cairosvg\n",
    "from PIL import Image\n",
    "grid_x, grid_y = 2, 1\n",
    "from gufe.visualization.mapping_visualization import draw_mapping\n",
    "\n",
    "def mapping_karto(liga, ligb, target, system):\n",
    "    d2d = Draw.rdMolDraw2D.MolDraw2DSVG(grid_x * 300, grid_y * 300, 300, 300)\n",
    "    mapping_filters = [\n",
    "            filter_ringbreak_changes,  # default\n",
    "            filter_ringsize_changes,  # default\n",
    "            filter_whole_rings_only,  # default\n",
    "        ]\n",
    "    mapper = kartograf.KartografAtomMapper(\n",
    "        atom_map_hydrogens=True,\n",
    "        additional_mapping_filter_functions=mapping_filters,\n",
    "    )\n",
    "    ligand_a = SmallMoleculeComponent(key_to_ligand[(liga, target, system)])\n",
    "    ligand_b = SmallMoleculeComponent(key_to_ligand[(ligb, target, system)])\n",
    "    mapping =  next(mapper.suggest_mappings(ligand_a, ligand_b))\n",
    "    svg_text = draw_mapping(mapping._compA_to_compB, mapping.componentA.to_rdkit(), mapping.componentB.to_rdkit(), d2d)\n",
    "    png_data = cairosvg.svg2png(bytestring=svg_text.encode('utf-8'))\n",
    "    image = Image.open(io.BytesIO(png_data))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "# for the neutral edges get the absolute difference between the 4 ns and 5 ns predictions\n",
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral)\n",
    "neutral_df = neutral_df[(neutral_df[\"Samples 5 ns DDG\"].notna()) & (neutral_df[\"Samples 4 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# get the abs error\n",
    "abs_diff = abs(neutral_df[\"Samples 4 ns DDG\"] - neutral_df[\"Samples 5 ns DDG\"])\n",
    "# get the top 3 and bottom 3 edges by abs error after added the absolute difference to the dataframe\n",
    "neutral_df[\"abs_diff\"] = abs_diff\n",
    "# sort the dataframe by the abs_diff column\n",
    "neutral_df = neutral_df.sort_values(by=\"abs_diff\", ascending=False)\n",
    "# get the top 3 and bottom 3 edges\n",
    "top_3_edges = neutral_df.head(3)\n",
    "bottom_3_edges = neutral_df.tail(3)\n",
    "# combine the two dataframes\n",
    "selected_edges = pd.concat([top_3_edges, bottom_3_edges], ignore_index=True)\n",
    "# Step 3: Plotting setup\n",
    "n = 3\n",
    "fig, axs = plt.subplots(2, n, figsize=(4 * n, 8), sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, row in selected_edges.iterrows():\n",
    "    ax = axs[i]\n",
    "    diffs = []\n",
    "    for i in range(1, 6):\n",
    "        diffs.append(abs(row[f\"Samples {i} ns DDG\"] - row[f\"Samples {5} ns DDG\"]))\n",
    "\n",
    "    ax.plot(np.arange(1, 6), diffs, marker='o')\n",
    "    ax.set_title(f\"{row['system group']}:{row['system name']}\")\n",
    "    # ax.set_xlabel('Time (ns)')\n",
    "    # ax.set_ylabel('ΔΔG (kcal/mol)')\n",
    "    # ax.legend()\n",
    "\n",
    "    # Optional: add molecule drawings\n",
    "    img = mapping_karto(row[\"ligand_A\"], row[\"ligand_B\"], row[\"system name\"], row[\"system group\"])\n",
    "    # img = Draw.MolsToImage([mol1, mol2], molsPerRow=2, subImgSize=(100,100))\n",
    "\n",
    "    imagebox = OffsetImage(img, zoom=0.25)\n",
    "    ab = AnnotationBbox(imagebox, (0.95, 0.05), frameon=True, xycoords='axes fraction',\n",
    "                        box_alignment=(1, -1.75))\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.supxlabel('Time (ns)', fontsize=16)\n",
    "    fig.supylabel(r\"$|\\Delta\\Delta G_{N} - \\Delta\\Delta G_{total}|$ kcal/mol\", fontsize=16)\n",
    "    plt.savefig(\"top_bottom_3_edges_neutral.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again for the charged edges\n",
    "charged_df = pd.DataFrame(per_ns_ddgs_charged)\n",
    "charged_df = charged_df[(charged_df[\"Samples 20 ns DDG\"].notna()) & (charged_df[\"Samples 16 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# get the abs error\n",
    "abs_diff = abs(charged_df[\"Samples 16 ns DDG\"] - charged_df[\"Samples 20 ns DDG\"])\n",
    "# get the top 3 and bottom 3 edges by abs error after added the absolute difference to the dataframe\n",
    "charged_df[\"abs_diff\"] = abs_diff\n",
    "# sort the dataframe by the abs_diff column\n",
    "charged_df = charged_df.sort_values(by=\"abs_diff\", ascending=False)\n",
    "# get the top 3 and bottom 3 edges\n",
    "top_3_edges = charged_df.head(3)\n",
    "bottom_3_edges = charged_df.tail(3)\n",
    "# combine the two dataframes\n",
    "selected_edges = pd.concat([top_3_edges, bottom_3_edges], ignore_index=True)\n",
    "# Step 3: Plotting setup\n",
    "n = 3\n",
    "fig, axs = plt.subplots(2, n, figsize=(4 * n, 8), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for i, row in selected_edges.iterrows():\n",
    "    ax = axs[i]\n",
    "    diffs = []\n",
    "    for i in range(1, 21):\n",
    "        diffs.append(abs(row[f\"Samples {i} ns DDG\"] - row[f\"Samples {20} ns DDG\"]))\n",
    "\n",
    "    ax.plot(np.arange(1, 21), diffs, marker='o')\n",
    "    ax.set_title(f\"{row['system group']}:{row['system name']}\")\n",
    "    # ax.set_xlabel('Time (ns)')\n",
    "    # ax.set_ylabel('ΔΔG (kcal/mol)')\n",
    "    # ax.legend()\n",
    "\n",
    "    # Optional: add molecule drawings\n",
    "    img = mapping_karto(row[\"ligand_A\"], row[\"ligand_B\"], row[\"system name\"], row[\"system group\"])\n",
    "    # img = Draw.MolsToImage([mol1, mol2], molsPerRow=2, subImgSize=(100,100))\n",
    "\n",
    "    imagebox = OffsetImage(img, zoom=0.25)\n",
    "    ab = AnnotationBbox(imagebox, (0.95, 0.05), frameon=True, xycoords='axes fraction',\n",
    "                        box_alignment=(1, -1.75))\n",
    "    ax.add_artist(ab)\n",
    "    plt.tight_layout()\n",
    "    fig.supxlabel('Time (ns)', fontsize=16)\n",
    "    fig.supylabel(r\"$|\\Delta\\Delta G_{N} - \\Delta\\Delta G_{total}|$ kcal/mol\", fontsize=16)\n",
    "    plt.savefig(\"top_bottom_3_edges_charged.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df which we can use for the boxplot, this should let use hue by public and private and have the change in DDG and the absolute error\n",
    "# do public first\n",
    "all_change_ddg_df = []\n",
    "for dataset, label in zip([pd.DataFrame(per_ns_ddgs_neutral), pd.DataFrame(per_ns_ddgs_neutral_private)], [\"Public\", \"Private\"]):\n",
    "    for _, row in dataset.iterrows():\n",
    "        # get the change in DDG between 4 ns and 5 ns\n",
    "        change_in_ddg = abs(row[\"Samples 4 ns DDG\"] - row[\"Samples 5 ns DDG\"])\n",
    "        # get the absolute error\n",
    "        abs_error = abs(row[\"exp DDG (kcal/mol)\"] - row[\"Samples 5 ns DDG\"])\n",
    "        all_change_ddg_df.append({\n",
    "            \"Change in DDG 4-5 ns\": \"< 0.5\" if change_in_ddg < 0.5 else \"> 0.5\",\n",
    "            \"abs DDG error\": abs_error,\n",
    "            \"ligand_A\": row[\"ligand_A\"],\n",
    "            \"ligand_B\": row[\"ligand_B\"],\n",
    "            \"dataset\": label\n",
    "        })\n",
    "all_change_ddg_df = pd.DataFrame(all_change_ddg_df)\n",
    "all_change_ddg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_change_ddg_df[(all_change_ddg_df[\"Change in DDG 4-5 ns\"] == \"> 0.5\") & (all_change_ddg_df[\"dataset\"] == \"Public\")].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot the absolute error distribution seperating edges with a change in ddg greater than 0.5 kcal/mol\n",
    "sns.boxplot(data=all_change_ddg_df, x=\"Change in DDG 4-5 ns\", y=\"abs DDG error\", hue=\"dataset\")\n",
    "plt.ylabel(r\"$|\\Delta\\Delta$G$_{calc} - \\Delta\\Delta$G$_{\\text{exp}}$| (kcal/mol)\", fontdict={\"fontsize\": 12})\n",
    "# plt.xticks([0, 1], [\"> 0.5 kcal/mol\", \"< 0.5 kcal/mol\"], fontsize=12)\n",
    "plt.xlabel(r\"$|\\Delta\\Delta$G$_{4ns} - \\Delta\\Delta$G$_{5ns}|$ (kcal/mol)\", fontdict={\"fontsize\": 12})\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(title=\"Dataset\", fontsize=12, title_fontsize=12)\n",
    "# add text to the top of the boxplots with the number of edges in each boxplot for the public and private datasets only for the > 0.5 kcal/mol boxplot\n",
    "# for i, change in enumerate([\"> 0.5\", \"< 0.5\"]):\n",
    "#     for j, dataset in [(-1, \"Public\"), (1,\"Private\")]:\n",
    "#         count = all_change_ddg_df[(all_change_ddg_df[\"Change in DDG 4-5 ns\"] == change) & (all_change_ddg_df[\"dataset\"] == dataset)].shape[0]\n",
    "#         plt.text(i + j * 0.2, -0.8, f\"{count}\", ha='center', va='bottom', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"absolute_error_boxplot_neutral_large_change_pub_private.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all neutral edges with a change in ddg greater than 0.5 kcal/mol\n",
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral_private)\n",
    "neutral_df = neutral_df[(neutral_df[\"Samples 5 ns DDG\"].notna()) & (neutral_df[\"Samples 4 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "# get the abs error\n",
    "abs_diff = abs(neutral_df[\"Samples 4 ns DDG\"] - neutral_df[\"Samples 5 ns DDG\"])\n",
    "neutral_large_change_df = neutral_df[abs_diff >= 0.5].copy(deep=True).reset_index(drop=True)\n",
    "neutral_small_change_df = neutral_df[abs_diff < 0.5].copy(deep=True).reset_index(drop=True)\n",
    "# create a single dataframe with small and large changes and the edge metrics for a box plot\n",
    "all_edge_data = []\n",
    "for _, row in neutral_large_change_df.iterrows():\n",
    "    for metric in [\"lomap_score\", \"shape_score\", \"volume_score\", \"mapping_rmsd_score\", \"morgan_tanimoto_similarity\", \"atom_pair_dice_similarity\", \"topological_torsion_dice_similarity\"]:\n",
    "        # grab the row from the edge dataframe\n",
    "        edge_row = private_edge_data[(private_edge_data[\"ligand_A\"] == row[\"ligand_A\"]) & (private_edge_data[\"ligand_B\"] == row[\"ligand_B\"]) & (private_edge_data[\"dataset_name\"] == row[\"system name\"]) & (private_edge_data[\"partner_id\"] == row[\"partner\"])].iloc[0]\n",
    "        data = {\n",
    "            \"Change in DDG 4-5 ns\": \">0.5\" if abs(row[\"Samples 4 ns DDG\"] - row[\"Samples 5 ns DDG\"]) > 0.5 else \"<0.5\",\n",
    "            \"metric\": metric.replace(\"_\", \"\\n\"),\n",
    "            \"value\": edge_row[metric],\n",
    "        }\n",
    "        all_edge_data.append(data)\n",
    "for _, row in neutral_small_change_df.iterrows():\n",
    "    for metric in [\"lomap_score\", \"shape_score\", \"volume_score\", \"mapping_rmsd_score\", \"morgan_tanimoto_similarity\", \"atom_pair_dice_similarity\", \"topological_torsion_dice_similarity\"]:\n",
    "        # grab the row from the edge dataframe\n",
    "        edge_row = private_edge_data[(private_edge_data[\"ligand_A\"] == row[\"ligand_A\"]) & (private_edge_data[\"ligand_B\"] == row[\"ligand_B\"]) & (private_edge_data[\"dataset_name\"] == row[\"system name\"]) & (private_edge_data[\"partner_id\"] == row[\"partner\"])].iloc[0]\n",
    "        data = {\n",
    "            \"Change in DDG 4-5 ns\": \"<0.5\" if abs(row[\"Samples 4 ns DDG\"] - row[\"Samples 5 ns DDG\"]) < 0.5 else \">0.5\",\n",
    "            \"metric\": metric.replace(\"_\", \"\\n\"),\n",
    "            \"value\": edge_row[metric],\n",
    "        }\n",
    "        all_edge_data.append(data)\n",
    "all_edge_data_df = pd.DataFrame(all_edge_data)\n",
    "# plot the boxplot\n",
    "sns.boxplot(data=all_edge_data_df, x=\"metric\", y=\"value\", hue=\"Change in DDG 4-5 ns\")\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=12)\n",
    "# rename the ledend title\n",
    "plt.legend(title=r\"$\\Delta\\Delta\\Delta$G$_{4-5}$\")\n",
    "plt.ylabel(\"Edge metric value\", fontdict={\"fontsize\": 12})\n",
    "plt.xlabel(\"Edge metric\", fontdict={\"fontsize\": 12})\n",
    "plt.savefig(\"edge_metrics_boxplot_neutral_large_change_private.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_df = pd.DataFrame(per_ns_ddgs_neutral)\n",
    "# get the number of edges in the charge ptp1b system\n",
    "neutral_df = neutral_df[(neutral_df[\"Samples 5 ns DDG\"].notna()) & (neutral_df[\"Samples 4 ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "system_name = \"ptp1b\"\n",
    "system_group = \"charge_annihilation_set\"\n",
    "system_edges = neutral_df[(neutral_df[\"system name\"] == system_name) & (neutral_df[\"system group\"] == system_group)].copy(deep=True).reset_index(drop=True)\n",
    "system_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncert_distribution_per_ns(df, ns_range):\n",
    "    all_data = []\n",
    "    for i in range(1, ns_range + 1):\n",
    "        # get the error for that many ns\n",
    "        temp_df = df[df[f\"Samples {i} ns dDDG\"].notna()].copy(deep=True).reset_index(drop=True)\n",
    "        for ddg_error in temp_df[f\"Samples {i} ns dDDG\"]:\n",
    "            all_data.append(\n",
    "                {\"value\": ddg_error, \"ns\": i}\n",
    "            )\n",
    "    tmp_all_data = pd.DataFrame(all_data)\n",
    "    sns.boxplot(data=tmp_all_data, x=\"ns\", y=\"value\", order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.6, dodge=True, fliersize=5, linewidth=None, whis=1.5, ax=None)\n",
    "    plt.xlabel(\"Sampling ns\")\n",
    "    plt.ylabel(r\"$dDDG_{N}$\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_uncert_distribution_per_ns(pd.DataFrame(per_ns_ddgs_neutral), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average distance to the final result per ns for each system\n",
    "# write the plots to file seperate the neutral and charged edges\n",
    "import pathlib\n",
    "def plot_distance_to_final_ddg_distribution_per_system(df, ns_range, plot_type):\n",
    "    nbootstrap = 1000\n",
    "    ci = 0.95\n",
    "    # calculate the mean change between x and ns_range with 95% CI\n",
    "    # get the final value using all simulation data\n",
    "    systems = df[\"system group\"].unique()\n",
    "    for system in systems:\n",
    "        system_folder = pathlib.Path(system)\n",
    "        system_folder.mkdir(exist_ok=True)\n",
    "        system_group_df = df[df[\"system group\"] == system].copy(deep=True).reset_index(drop=True)\n",
    "        targets = system_group_df[\"system name\"].unique()\n",
    "        for target in targets:\n",
    "            changes_in_ddg = []\n",
    "            print(f\"Running for system:{system} and target: {target}\")\n",
    "            target_folder = system_folder.joinpath(target)\n",
    "            target_folder.mkdir(exist_ok=True)\n",
    "            target_df = system_group_df[system_group_df[\"system name\"] == target].copy(deep=True).reset_index(drop=True)\n",
    "            # for each ns compute the abs distance to the fnal value and plot the convergence\n",
    "            for i in range(1, ns_range):\n",
    "                # get the DDG values for I sampling time\n",
    "                temp_df = target_df[(target_df[f\"Samples {i} ns DDG\"].notna()) & (target_df[f\"Samples {ns_range} ns DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "                # get the difference between this ns and the final value using all data\n",
    "                change_in_ddg = abs(temp_df[f\"Samples {i} ns DDG\"] - temp_df[f\"Samples {ns_range} ns DDG\"])\n",
    "                mean_change = change_in_ddg.mean()\n",
    "                # get the bootstrap CI\n",
    "                mean_values = []\n",
    "                for _ in range(1000):\n",
    "                    sample_data =np.zeros_like(change_in_ddg)\n",
    "                    for x, y in enumerate(\n",
    "                        np.random.choice(np.arange(len(change_in_ddg)), size=[len(change_in_ddg)], replace=True)\n",
    "                    ):\n",
    "                        sample_data[x] = change_in_ddg[y]\n",
    "                    mean_values.append(sample_data.mean())\n",
    "                # sort and get the ci\n",
    "                mean_values = np.sort(mean_values)\n",
    "                low_frac = (1.0 - ci) / 2.0\n",
    "                high_frac = 1.0 - low_frac\n",
    "                change_stats = {\n",
    "                    \"mean change\": mean_change,\n",
    "                    \"extra ns\": i\n",
    "                }\n",
    "                change_stats[\"low\"] = mean_values[int(np.floor(nbootstrap * low_frac))]\n",
    "                change_stats[\"high\"] = mean_values[int(np.ceil(nbootstrap * high_frac))]\n",
    "\n",
    "                changes_in_ddg.append(change_stats)\n",
    "            temp_change_df = pd.DataFrame(changes_in_ddg)\n",
    "            x_labels = [j for j in range(1, ns_range)]\n",
    "            plt.scatter(x_labels, temp_change_df[\"mean change\"])\n",
    "            plt.errorbar(x_labels, temp_change_df[\"mean change\"], yerr=(temp_change_df[\"mean change\"] - temp_change_df[\"low\"], temp_change_df[\"high\"] - temp_change_df[\"mean change\"]), capsize=4)\n",
    "            plt.fill_between(np.arange(ns_range + 1), y1=[0.15 for _ in range(ns_range + 1)], alpha=0.3, color=\"lightgreen\")\n",
    "            plt.fill_between(np.arange(ns_range + 1), y1=[0.15 for _ in range(ns_range + 1)], y2=[0.3 for _ in range(ns_range + 1)], alpha=0.3, color=\"orange\")\n",
    "            plt.ylim(0, 3)\n",
    "            plt.xlim(0, ns_range)\n",
    "            plt.grid()\n",
    "            plt.title(f\"System: {system}, target: {target}\")\n",
    "            plt.xlabel(\"Sampling ns\")\n",
    "            plt.ylabel(r\"Average $|DDG_{N} - DDG_{total}|$\")\n",
    "            plt.xticks(x_labels)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(target_folder.joinpath(f\"abs_distance_to_final_ddg_{plot_type}.png\"))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_to_final_ddg_distribution_per_system(pd.DataFrame(per_ns_ddgs_neutral), 5, \"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each 1/5 of the sampling time calculate the sub abs 1kcal/mol error stats breakdown\n",
    "# we need to make a new df combinging the charged and neutral edges \n",
    "combined_per_ns_data = []\n",
    "for _, row in normal_edge_data.iterrows():\n",
    "    if np.isnan(row[\"exp DDG (kcal/mol)\"]):\n",
    "        continue\n",
    "    if row[\"alchemical_charge_difference\"] == 0:\n",
    "        total_ns = 5\n",
    "    else:\n",
    "        total_ns = 20\n",
    "    cumulative_data_row = {\n",
    "        \"system group\": row[\"system group\"],\n",
    "        \"system name\": row[\"system name\"],\n",
    "        \"ligand_A\": row[\"ligand_A\"],\n",
    "        \"ligand_B\": row[\"ligand_B\"],\n",
    "        \"exp DDG (kcal/mol)\": row[\"exp DDG (kcal/mol)\"],\n",
    "        \"exp dDDG (kcal/mol)\": row[\"exp dDDG (kcal/mol)\"],\n",
    "        \"alchemical_charge_difference\": row[\"alchemical_charge_difference\"]\n",
    "    }\n",
    "    # workout the estimate of DDG for each 1/5 of total ns\n",
    "    temp_cumulative_data = cumulative_data[(cumulative_data[\"system group\"] == row[\"system group\"]) & (cumulative_data[\"system name\"] == row[\"system name\"])].copy(deep=True).reset_index(drop=True)\n",
    "    complex_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"complex\")]\n",
    "    solvent_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"solvent\")]\n",
    "    fith_sample_time = int(total_ns / 5)\n",
    "\n",
    "    for i in range(fith_sample_time, total_ns + 1, fith_sample_time):\n",
    "        per_ns_complex = complex_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_complex_error = complex_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        per_ns_solvent = solvent_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_solvent_error = solvent_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        cumulative_data_row[f\"Samples {int((i/total_ns)*100)}% DDG\"] = per_ns_complex - per_ns_solvent\n",
    "        cumulative_data_row[f\"Samples {int((i/total_ns)*100)}% dDDG\"] = (per_ns_complex_error ** 2 + per_ns_solvent_error ** 2) ** 0.5\n",
    "    combined_per_ns_data.append(cumulative_data_row)\n",
    "combined_per_ns_df = pd.DataFrame(combined_per_ns_data)\n",
    "combined_per_ns_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again for the private data\n",
    "combined_per_ns_data_private = []\n",
    "for _, row in private_edge_data.iterrows():\n",
    "    if np.isnan(row[\"exp DDG (kcal/mol)\"]):\n",
    "        continue\n",
    "    if row[\"alchemical_charge_difference\"] == 0:\n",
    "        total_ns = 5\n",
    "    else:\n",
    "        total_ns = 20\n",
    "    cumulative_data_row = {\n",
    "        \"partner\": row[\"partner_id\"],\n",
    "        \"system name\": row[\"dataset_name\"],\n",
    "        \"ligand_A\": row[\"ligand_A\"],\n",
    "        \"ligand_B\": row[\"ligand_B\"],\n",
    "        \"exp DDG (kcal/mol)\": row[\"exp DDG (kcal/mol)\"],\n",
    "        \"exp dDDG (kcal/mol)\": row[\"exp dDDG (kcal/mol)\"],\n",
    "        \"alchemical_charge_difference\": row[\"alchemical_charge_difference\"]\n",
    "    }\n",
    "    # workout the estimate of DDG for each 1/5 of total ns\n",
    "    temp_cumulative_data = private_cumulative_data[(private_cumulative_data[\"partner_id\"] == row[\"partner_id\"]) & (private_cumulative_data[\"dataset_name\"] == row[\"dataset_name\"])].copy(deep=True).reset_index(drop=True)\n",
    "    complex_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"complex\")]\n",
    "    solvent_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"solvent\")]\n",
    "    fith_sample_time = int(total_ns / 5)\n",
    "\n",
    "    for i in range(fith_sample_time, total_ns + 1, fith_sample_time):\n",
    "        per_ns_complex = complex_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_complex_error = complex_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        per_ns_solvent = solvent_data[f\"Samples {i}ns (subsample) DG\"].mean()\n",
    "        per_ns_solvent_error = solvent_data[f\"Samples {i}ns (subsample) DG\"].std()\n",
    "        cumulative_data_row[f\"Samples {int((i/total_ns)*100)}% DDG\"] = per_ns_complex - per_ns_solvent\n",
    "        cumulative_data_row[f\"Samples {int((i/total_ns)*100)}% dDDG\"] = (per_ns_complex_error ** 2 + per_ns_solvent_error ** 2) ** 0.5\n",
    "    combined_per_ns_data_private.append(cumulative_data_row)\n",
    "combined_per_ns_df_private = pd.DataFrame(combined_per_ns_data_private)\n",
    "combined_per_ns_df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stats_breakdown(df):\n",
    "    # for each 1/5 of data find all edges with abs error under 1 kcal/mol\n",
    "    # calculate the MUE and rho and number of edges under the threshold\n",
    "    break_down_data = []\n",
    "    for i in range(20, 120, 20):\n",
    "        # grab notna results\n",
    "        temp_df = df[(df[f\"Samples {i}% DDG\"].notna()) & (df[f\"Samples {i}% dDDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "        error_thresh = abs(temp_df[\"exp DDG (kcal/mol)\"] - temp_df[f\"Samples {i}% DDG\"]) < 1\n",
    "        error_thresh_df = temp_df[error_thresh].copy(deep=True).reset_index(drop=True)\n",
    "        sample_data = {\"ns\": i, \"no\": len(error_thresh_df)}\n",
    "        for stat in [\"MUE\", \"rho\"]:\n",
    "            s = stats.bootstrap_statistic(\n",
    "                y_true=error_thresh_df[\"exp DDG (kcal/mol)\"],\n",
    "                y_pred=error_thresh_df[f\"Samples {i}% DDG\"],\n",
    "                dy_true=error_thresh_df[\"exp dDDG (kcal/mol)\"],\n",
    "                dy_pred=error_thresh_df[f\"Samples {i}% dDDG\"],\n",
    "                statistic=stat,\n",
    "            )\n",
    "            sample_data[stat] = s[\"mle\"]\n",
    "        break_down_data.append(sample_data)\n",
    "    return pd.DataFrame(break_down_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stats_breakdown(combined_per_ns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the change in DDG at N compared to the full data averaged across all datasets using the % of the sampling data\n",
    "# to combine the charge changes with the neutral edges\n",
    "def plot_distribution_of_ddg_distance_per_system(df):\n",
    "    all_data = []\n",
    "    for i in range(20, 120, 20):\n",
    "        # get the DDG values for I sampling time\n",
    "        temp_df = df[(df[f\"Samples {i}% DDG\"].notna()) & (df[f\"Samples 100% DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "        # for each system calculate the average\n",
    "        for system in temp_df[\"system group\"].unique():\n",
    "            system_df = temp_df[temp_df[\"system group\"] == system].copy(deep=True).reset_index(drop=True)\n",
    "            for target in system_df[\"system name\"].unique():\n",
    "                target_df = system_df[system_df[\"system name\"] == target].copy(deep=True).reset_index(drop=True)\n",
    "                # get the difference between this ns and the final value using all data\n",
    "                mean_change_in_ddg = np.mean(abs(target_df[f\"Samples {i}% DDG\"] - target_df[f\"Samples 100% DDG\"]))\n",
    "                all_data.append(\n",
    "                    {\"value\": mean_change_in_ddg, \"ns\": i, \"system group\": system, \"system name\": target}\n",
    "                )\n",
    "    tmp_all_data = pd.DataFrame(all_data)\n",
    "    # return tmp_all_data\n",
    "    sns.boxplot(data=tmp_all_data, x=\"ns\", y=\"value\", order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.6, dodge=True, fliersize=5, linewidth=None, whis=1.5, ax=None)\n",
    "    # add annotations on the plot for the outliers for the 80% sampling boxplot \n",
    "    j = 0\n",
    "    for i, row in tmp_all_data.iterrows():\n",
    "        if row[\"ns\"] != 80:\n",
    "            continue\n",
    "        if row[\"value\"] > 0.2:\n",
    "            print(row)\n",
    "            # name conversion\n",
    "            name_to_new_name = {\"bayer_macrocycles\": \"macrocycle\", \"charge_annihilation_set\": \"charged\", \"miscellaneous_set\": \"misc\"}\n",
    "            system_group = name_to_new_name.get(row[\"system group\"], row[\"system group\"])\n",
    "            if row[\"value\"] > 0.3:\n",
    "                x = 2.5\n",
    "                offset = 0.2\n",
    "                ha = \"center\"\n",
    "            else:\n",
    "                x = 4 - 0.24 * j\n",
    "                offset = 0.1 * j\n",
    "                j += 1\n",
    "                if row[\"system name\"] in [\"shp2\", \"eg5\"]:\n",
    "                    ha = \"left\"\n",
    "            plt.annotate(f\"{system_group}:{row['system name']}\", xy=(3, row[\"value\"]), xytext=(x, row[\"value\"] + offset), ha=ha, color='darkred', arrowprops=dict(arrowstyle='->', color='darkred', lw=1.2))\n",
    "    plt.xlabel(\"Sampling %\", fontdict={\"fontsize\": 12})\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.ylabel(r\"$<|\\Delta\\Delta$G$_{N} - \\Delta\\Delta$G$_{total}|>_{system}$\", fontdict={\"fontsize\": 12})\n",
    "    plt.savefig(\"distribution_of_ddg_distance_per_system.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_of_ddg_distance_per_system(combined_per_ns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_average_distance_to_ddg_df = plot_distribution_of_ddg_distance_per_system(combined_per_ns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_average_distance_to_ddg_df[system_average_distance_to_ddg_df[\"ns\"] == 80].sort_values(\"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the private dataset\n",
    "def plot_distribution_of_ddg_distance_per_system_private(df):\n",
    "    all_data = []\n",
    "    for i in range(20, 120, 20):\n",
    "        # get the DDG values for I sampling time\n",
    "        temp_df = df[(df[f\"Samples {i}% DDG\"].notna()) & (df[f\"Samples 100% DDG\"].notna())].copy(deep=True).reset_index(drop=True)\n",
    "        # for each system calculate the average\n",
    "        for system in temp_df[\"partner\"].unique():\n",
    "            system_df = temp_df[temp_df[\"partner\"] == system].copy(deep=True).reset_index(drop=True)\n",
    "            for target in system_df[\"system name\"].unique():\n",
    "                target_df = system_df[system_df[\"system name\"] == target].copy(deep=True).reset_index(drop=True)\n",
    "                # get the difference between this ns and the final value using all data\n",
    "                mean_change_in_ddg = np.mean(abs(target_df[f\"Samples {i}% DDG\"] - target_df[f\"Samples 100% DDG\"]))\n",
    "                all_data.append(\n",
    "                    {\"value\": mean_change_in_ddg, \"ns\": i, \"system group\": system, \"system name\": target}\n",
    "                )\n",
    "    tmp_all_data = pd.DataFrame(all_data)\n",
    "    # return tmp_all_data\n",
    "    sns.boxplot(data=tmp_all_data, x=\"ns\", y=\"value\", order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.6, dodge=True, fliersize=5, linewidth=None, whis=1.5, ax=None)\n",
    "    # add annotations on the plot for the outliers for the 80% sampling boxplot \n",
    "    j = 0\n",
    "    for i, row in tmp_all_data.iterrows():\n",
    "        if row[\"ns\"] != 80:\n",
    "            continue\n",
    "        if row[\"value\"] > 0.2:\n",
    "            print(row)\n",
    "            # name conversion\n",
    "            name_to_new_name = {\"bayer_macrocycles\": \"macrocycle\", \"charge_annihilation_set\": \"charged\", \"miscellaneous_set\": \"misc\"}\n",
    "            system_group = name_to_new_name.get(row[\"system group\"], row[\"system group\"])\n",
    "            if row[\"value\"] > 0.3:\n",
    "                x = 3.5\n",
    "                offset = 0.2\n",
    "                ha = \"center\"\n",
    "            else:\n",
    "                ha = \"center\"\n",
    "                x = 4 - 0.24 * j\n",
    "                offset = 0.1 * j\n",
    "                j += 1\n",
    "                if row[\"system name\"] in [\"shp2\", \"eg5\"]:\n",
    "                    ha = \"left\"\n",
    "            plt.annotate(f\"{system_group}:{row['system name']}\", xy=(3, row[\"value\"]), xytext=(x, row[\"value\"] + offset), ha=ha, color='darkred', arrowprops=dict(arrowstyle='->', color='darkred', lw=1.2))\n",
    "    plt.xlabel(\"Sampling %\", fontdict={\"fontsize\": 12})\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.ylabel(r\"$<|\\Delta\\Delta$G$_{N} - \\Delta\\Delta$G$_{total}|>_{system}$\", fontdict={\"fontsize\": 12})\n",
    "    plt.savefig(\"distribution_of_ddg_distance_per_system_private.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_of_ddg_distance_per_system_private(combined_per_ns_df_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_edge_data[\"partner_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "janB_1 = private_edge_data[(private_edge_data[\"partner_id\"] == \"EliLilly\") & (private_edge_data[\"dataset_name\"] == \"Project1\") ].copy(deep=True).reset_index(drop=True)\n",
    "lilly_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot the lomap scores for roche D vs all other systems\n",
    "other_systems = private_edge_data[(private_edge_data[\"partner_id\"] != \"Roche\") & (private_edge_data[\"dataset_name\"] != \"target_D\")].copy(deep=True).reset_index(drop=True)\n",
    "# boxplot the lomap scores for roche D vs all other systems\n",
    "sns.boxplot(data=private_edge_data, y=\"lomap_score\", x=0)\n",
    "sns.boxplot(data=roche_D, y=\"lomap_score\", x=1)\n",
    "sns.boxplot(data=janB_1, y=\"lomap_score\", x=2)\n",
    "sns.boxplot(data=lilly_1, y=\"lomap_score\", x=3)\n",
    "plt.ylabel(\"LOMAP score\", fontdict={\"fontsize\": 12})\n",
    "plt.xticks([0, 1, 2, 3], [\"All systems\", \"Roche D\", \"Janssen\\nSystemB set1\", \"EliLilly\\nProject1\"], fontsize=12)\n",
    "plt.xlabel(\"System\", fontdict={\"fontsize\": 12})\n",
    "plt.savefig(\"lomap_score_boxplot_for_slow_private_systems.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_average_private[system_average_private[\"ns\"] == 80].sort_values(\"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy if we do not do any subsampling\n",
    "# build another DF with the nonsubsampled data from 100% of the simulated data\n",
    "combined_per_ns__no_sub_data = []\n",
    "for _, row in normal_edge_data.iterrows():\n",
    "    if row[\"alchemical_charge_difference\"] == 0:\n",
    "        total_ns = 5\n",
    "    else:\n",
    "        total_ns = 20\n",
    "\n",
    "    cumulative_data_row = {\n",
    "        \"system group\": row[\"system group\"],\n",
    "        \"system name\": row[\"system name\"],\n",
    "        \"ligand_A\": row[\"ligand_A\"],\n",
    "        \"ligand_B\": row[\"ligand_B\"],\n",
    "        \"exp DDG (kcal/mol)\": row[\"exp DDG (kcal/mol)\"],\n",
    "        \"exp dDDG (kcal/mol)\": row[\"exp dDDG (kcal/mol)\"],\n",
    "        \"alchemical_charge_difference\": row[\"alchemical_charge_difference\"]\n",
    "    }\n",
    "    # workout the estimate of DDG using all of the data\n",
    "    temp_cumulative_data = cumulative_data[(cumulative_data[\"system group\"] == row[\"system group\"]) & (cumulative_data[\"system name\"] == row[\"system name\"])].copy(deep=True).reset_index(drop=True)\n",
    "    complex_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"complex\")]\n",
    "    solvent_data = temp_cumulative_data[(temp_cumulative_data[\"ligand_A\"] == row[\"ligand_A\"]) & (temp_cumulative_data[\"ligand_B\"] == row[\"ligand_B\"]) & (temp_cumulative_data[\"phase\"] == \"solvent\")]\n",
    "\n",
    "    per_ns_complex = complex_data[f\"Samples {total_ns}ns DG\"].mean()\n",
    "    per_ns_complex_error = complex_data[f\"Samples {total_ns}ns DG\"].std()\n",
    "    per_ns_solvent = solvent_data[f\"Samples {total_ns}ns DG\"].mean()\n",
    "    per_ns_solvent_error = solvent_data[f\"Samples {total_ns}ns DG\"].std()\n",
    "    cumulative_data_row[f\"All samples DDG\"] = per_ns_complex - per_ns_solvent\n",
    "    cumulative_data_row[f\"All samples dDDG\"] = (per_ns_complex_error ** 2 + per_ns_solvent_error ** 2) ** 0.5\n",
    "\n",
    "    combined_per_ns__no_sub_data.append(cumulative_data_row)\n",
    "combined_per_ns_df_no_sub = pd.DataFrame(combined_per_ns__no_sub_data)\n",
    "combined_per_ns_df_no_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ddgs(df):\n",
    "    return _master_plot(\n",
    "        x=df[\"exp DDG (kcal/mol)\"],\n",
    "        y=df[\"All samples DDG\"],\n",
    "        xerr=df[\"exp dDDG (kcal/mol)\"],\n",
    "        yerr=df[\"All samples dDDG\"],\n",
    "        scatter_kwargs={\"edgecolors\": 'black', \"linewidth\":0.8},\n",
    "        figsize=5,\n",
    "        statistic_type=\"mle\",\n",
    "        xy_lim=[-12, 12]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ddgs(combined_per_ns_df_no_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_down_data_no_sub = []\n",
    "\n",
    "# grab notna results\n",
    "error_thresh = abs(combined_per_ns_df_no_sub[\"exp DDG (kcal/mol)\"] - combined_per_ns_df_no_sub[f\"All samples DDG\"]) < 1\n",
    "error_thresh_df = combined_per_ns_df_no_sub[error_thresh].copy(deep=True).reset_index(drop=True)\n",
    "sample_data = {\"no\": len(error_thresh_df)}\n",
    "for stat in [\"MUE\", \"rho\"]:\n",
    "    s = stats.bootstrap_statistic(\n",
    "        y_true=error_thresh_df[\"exp DDG (kcal/mol)\"],\n",
    "        y_pred=error_thresh_df[f\"All samples DDG\"],\n",
    "        dy_true=error_thresh_df[\"exp dDDG (kcal/mol)\"],\n",
    "        dy_pred=error_thresh_df[f\"All samples dDDG\"],\n",
    "        statistic=stat,\n",
    "    )\n",
    "    sample_data[stat] = s[\"mle\"]\n",
    "break_down_data_no_sub.append(sample_data)\n",
    "pd.DataFrame(break_down_data_no_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asapdiscovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
